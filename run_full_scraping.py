#!/usr/bin/env python3
"""
ì „ì²´ 750ê°œ ë©”íŠ¸ë¦­ ìµœì¢… ìˆ˜ì§‘ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

from final_scraper import FinalScraper
import json

def main():
    """ì „ì²´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤í–‰"""
    scraper = FinalScraper()
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    print("ğŸš€ ì „ì²´ 750ê°œ IRIS+ ë©”íŠ¸ë¦­ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
    print("â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 20-25ë¶„")
    print("ğŸ’¾ ë°°ì¹˜ë³„ ì¤‘ê°„ ì €ì¥ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    print()
    
    base_data = scraper.load_base_metrics()
    
    if not base_data:
        print("âŒ ê¸°ì¡´ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_metrics = len(base_data['metrics'])
    print(f"ğŸ“Š ì²˜ë¦¬í•  ë©”íŠ¸ë¦­: {total_metrics}ê°œ")
    
    # ì „ì²´ ì²˜ë¦¬
    final_data = scraper.process_all_metrics(base_data, batch_size=50)
    
    # ìµœì¢… ì €ì¥
    final_filename = "data/iris_metrics_complete.json"
    with open(final_filename, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    # ê²°ê³¼ í†µê³„
    successful = sum(1 for m in final_data['metrics'] if m.get('details', {}).get('success', False))
    
    print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ğŸ“ ìµœì¢… íŒŒì¼: {final_filename}")
    print(f"ğŸ“Š ì„±ê³µë¥ : {successful}/{total_metrics}ê°œ ({successful/total_metrics*100:.1f}%)")
    
    # ì„¹ì…˜ë³„ í†µê³„
    section_stats = {}
    for metric in final_data['metrics']:
        if metric.get('details', {}).get('success', False):
            details = metric['details']
            for key in details:
                if key not in ['success', 'scraped_at', 'error']:
                    if key not in section_stats:
                        section_stats[key] = 0
                    section_stats[key] += 1
    
    print(f"\nğŸ“‹ ì„¹ì…˜ë³„ ìˆ˜ì§‘ í†µê³„:")
    for section, count in sorted(section_stats.items()):
        print(f"  {section}: {count}ê°œ")

if __name__ == "__main__":
    main()
