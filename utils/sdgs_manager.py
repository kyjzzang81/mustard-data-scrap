"""
SDGs ë°ì´í„° í•˜ì´ë¸Œë¦¬ë“œ ê´€ë¦¬ ì‹œìŠ¤í…œ
"""
import json
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from data_catalog import DataCatalog, DataFile, DataSource
from utils.sdgs_analyzer import SDGsAnalyzer

class SDGsManager:
    """SDGs ë°ì´í„° í•˜ì´ë¸Œë¦¬ë“œ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.catalog = DataCatalog()
        self.analyzer = SDGsAnalyzer()
        self.sdgs_data_path = Path("data_sources/un_sdg")
        self.lib_path = Path("lib")
        
    def migrate_to_structured_storage(self):
        """lib í´ë”ì˜ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ ì €ì¥ì†Œë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        print("ğŸ”„ SDGs ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        # 1. ì›ë³¸ íŒŒì¼ë“¤ì„ raw í´ë”ë¡œ ë³µì‚¬
        self._copy_original_files()
        
        # 2. ë©”íƒ€ë°ì´í„° ë¶„ì„ ë° ì¶”ì¶œ
        analysis_data = self.analyzer.extract_structured_data()
        
        # 3. ë¶„ì„ ê²°ê³¼ë¥¼ processed í´ë”ì— ì €ì¥
        self._save_analysis_results(analysis_data)
        
        # 4. ë°ì´í„° ì¹´íƒˆë¡œê·¸ì— ë“±ë¡
        self._register_in_catalog(analysis_data)
        
        print("âœ… SDGs ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    
    def _copy_original_files(self):
        """ì›ë³¸ íŒŒì¼ë“¤ì„ raw í´ë”ë¡œ ë³µì‚¬"""
        print("ğŸ“ ì›ë³¸ íŒŒì¼ ë³µì‚¬ ì¤‘...")
        
        # ë©”íƒ€ë°ì´í„° PDF íŒŒì¼ë“¤ ë³µì‚¬
        metadata_dest = self.sdgs_data_path / "raw" / "metadata"
        metadata_dest.mkdir(parents=True, exist_ok=True)
        
        for pdf_file in self.lib_path.glob("SDG-indicator-metadata/*.pdf"):
            dest_file = metadata_dest / pdf_file.name
            shutil.copy2(pdf_file, dest_file)
            print(f"  ğŸ“„ ë³µì‚¬ë¨: {pdf_file.name}")
        
        # í”„ë ˆì„ì›Œí¬ Excel íŒŒì¼ ë³µì‚¬
        framework_dest = self.sdgs_data_path / "raw" / "framework"
        framework_dest.mkdir(parents=True, exist_ok=True)
        
        excel_file = self.lib_path / "Global-Indicator-Framework-after-2025-review-English.xlsx"
        if excel_file.exists():
            dest_file = framework_dest / excel_file.name
            shutil.copy2(excel_file, dest_file)
            print(f"  ğŸ“Š ë³µì‚¬ë¨: {excel_file.name}")
    
    def _save_analysis_results(self, analysis_data: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ë¥¼ processed í´ë”ì— ì €ì¥"""
        print("ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        processed_dir = self.sdgs_data_path / "processed"
        processed_dir.mkdir(parents=True, exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì €ì¥
        metadata_file = processed_dir / f"sdgs_metadata_analysis_{datetime.now().strftime('%Y%m%d')}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        # ê°œë³„ ì§€í‘œë³„ ë©”íƒ€ë°ì´í„° ì €ì¥
        indicators_dir = processed_dir / "indicators"
        indicators_dir.mkdir(exist_ok=True)
        
        for metadata in analysis_data.get("metadata_files", []):
            indicator_file = indicators_dir / f"indicator_{metadata['indicator_id']}.json"
            with open(indicator_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"  âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: {metadata_file}")
    
    def _register_in_catalog(self, analysis_data: Dict[str, Any]):
        """ë°ì´í„° ì¹´íƒˆë¡œê·¸ì— ë“±ë¡"""
        print("ğŸ“‹ ë°ì´í„° ì¹´íƒˆë¡œê·¸ì— ë“±ë¡ ì¤‘...")
        
        # SDGs ë°ì´í„° ì†ŒìŠ¤ ë“±ë¡ (ì•„ì§ ì—†ë‹¤ë©´)
        if not self.catalog.get_data_source("un_sdg"):
            sdgs_source = DataSource(
                code="un_sdg",
                name="UN Sustainable Development Goals",
                description="ìœ ì—” ì§€ì†ê°€ëŠ¥ë°œì „ëª©í‘œ ì§€í‘œ ë° ë©”íƒ€ë°ì´í„°",
                website="https://unstats.un.org/sdgs/",
                category="sustainability",
                update_frequency="annual"
            )
            self.catalog.register_data_source(sdgs_source)
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ ë“±ë¡
        for metadata in analysis_data.get("metadata_files", []):
            data_file = DataFile(
                filename=metadata["filename"],
                data_source="un_sdg",
                data_type="metadata",
                version="v1",
                file_path=metadata["file_path"],
                file_size=metadata["size_bytes"],
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                description=f"SDG ì§€í‘œ {metadata['indicator_id']} ë©”íƒ€ë°ì´í„°",
                tags=["sdg", "metadata", f"goal_{metadata['goal']}", f"indicator_{metadata['indicator_id']}"]
            )
            self.catalog.register_data_file(data_file)
        
        # í”„ë ˆì„ì›Œí¬ íŒŒì¼ ë“±ë¡
        if analysis_data.get("framework_data"):
            framework_file = DataFile(
                filename="Global-Indicator-Framework-after-2025-review-English.xlsx",
                data_source="un_sdg",
                data_type="framework",
                version="v1",
                file_path="data_sources/un_sdg/raw/framework/Global-Indicator-Framework-after-2025-review-English.xlsx",
                file_size=Path("data_sources/un_sdg/raw/framework/Global-Indicator-Framework-after-2025-review-English.xlsx").stat().st_size,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                description="SDGs ê¸€ë¡œë²Œ ì§€í‘œ í”„ë ˆì„ì›Œí¬ (2025ë…„ ë¦¬ë·° í›„)",
                tags=["sdg", "framework", "indicators", "global"]
            )
            self.catalog.register_data_file(framework_file)
    
    def generate_supabase_import_data(self) -> Dict[str, Any]:
        """Supabase ì„í¬íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        print("ğŸ”„ Supabase ì„í¬íŠ¸ìš© ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ë¶„ì„ ë°ì´í„° ë¡œë“œ
        analysis_file = self.sdgs_data_path / "processed" / f"sdgs_metadata_analysis_{datetime.now().strftime('%Y%m%d')}.json"
        if not analysis_file.exists():
            print("âŒ ë¶„ì„ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return {}
        
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        
        # Supabase í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        supabase_data = {
            "sdg_indicators": [],
            "sdg_metadata_files": [],
            "sdg_framework_data": []
        }
        
        # ì§€í‘œ ë°ì´í„° ë³€í™˜
        for metadata in analysis_data.get("metadata_files", []):
            indicator = {
                "indicator_id": metadata["indicator_id"],
                "goal_id": int(metadata["goal"]) if metadata["goal"].isdigit() else None,
                "title": metadata["title"],
                "description": f"SDG ì§€í‘œ {metadata['indicator_id']} ë©”íƒ€ë°ì´í„°"
            }
            supabase_data["sdg_indicators"].append(indicator)
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë³´
            metadata_file = {
                "indicator_id": metadata["indicator_id"],
                "filename": metadata["filename"],
                "file_path": metadata["file_path"],
                "file_size_bytes": metadata["size_bytes"],
                "file_type": "pdf",
                "title": metadata["title"],
                "pages": metadata["pages"],
                "is_processed": True,
                "processing_status": "completed"
            }
            supabase_data["sdg_metadata_files"].append(metadata_file)
        
        # í”„ë ˆì„ì›Œí¬ ë°ì´í„° ë³€í™˜
        if analysis_data.get("framework_data"):
            framework_data = {
                "framework_version": "2025-review",
                "data_source": "UN Statistics Division",
                "raw_data": analysis_data["framework_data"],
                "processed_data": analysis_data["framework_data"]
            }
            supabase_data["sdg_framework_data"].append(framework_data)
        
        # Supabase í˜•ì‹ íŒŒì¼ ì €ì¥
        supabase_file = self.sdgs_data_path / "processed" / f"sdgs_supabase_format_{datetime.now().strftime('%Y%m%d')}.json"
        with open(supabase_file, 'w', encoding='utf-8') as f:
            json.dump(supabase_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Supabase í˜•ì‹ ë°ì´í„° ìƒì„±ë¨: {supabase_file}")
        return supabase_data
    
    def get_file_access_info(self) -> Dict[str, Any]:
        """íŒŒì¼ ì ‘ê·¼ ì •ë³´ ì œê³µ"""
        return {
            "file_system": {
                "raw_data_path": str(self.sdgs_data_path / "raw"),
                "processed_data_path": str(self.sdgs_data_path / "processed"),
                "total_files": len(list(self.sdgs_data_path.rglob("*"))),
                "total_size_mb": sum(f.stat().st_size for f in self.sdgs_data_path.rglob("*") if f.is_file()) / (1024 * 1024)
            },
            "database": {
                "schema_file": "config/sdgs_schema.sql",
                "tables": ["sdg_goals", "sdg_indicators", "sdg_metadata_files", "sdg_framework_data", "sdg_country_data"],
                "recommended_use": "êµ¬ì¡°í™”ëœ ì¿¼ë¦¬, ê´€ê³„í˜• ë¶„ì„, ì‹¤ì‹œê°„ API ì ‘ê·¼"
            },
            "recommendations": {
                "file_system": "ì›ë³¸ íŒŒì¼ ë³´ê´€, ì˜¤í”„ë¼ì¸ ì ‘ê·¼, ê°„ë‹¨í•œ íŒŒì¼ ê´€ë¦¬",
                "database": "ë³µì¡í•œ ì¿¼ë¦¬, ë‹¤ë¥¸ ë°ì´í„°ì™€ì˜ í†µí•©, ì‹¤ì‹œê°„ ë¶„ì„",
                "hybrid": "ì›ë³¸ì€ íŒŒì¼ë¡œ, ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°í™”ëœ ë°ì´í„°ëŠ” DBë¡œ"
            }
        }

if __name__ == "__main__":
    manager = SDGsManager()
    
    print("ğŸš€ SDGs ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘...")
    
    # 1. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    manager.migrate_to_structured_storage()
    
    # 2. Supabase ì„í¬íŠ¸ ë°ì´í„° ìƒì„±
    supabase_data = manager.generate_supabase_import_data()
    
    # 3. ì ‘ê·¼ ì •ë³´ ì¶œë ¥
    access_info = manager.get_file_access_info()
    print("\nğŸ“Š íŒŒì¼ ì ‘ê·¼ ì •ë³´:")
    print(json.dumps(access_info, indent=2, ensure_ascii=False))
