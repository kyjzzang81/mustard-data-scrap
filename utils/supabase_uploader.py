#!/usr/bin/env python3
"""
ë³€í™˜ëœ ë°ì´í„°ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” ë„êµ¬
"""

import json
import os
import requests
from datetime import datetime
import logging
from typing import Dict, List, Optional
from convert_to_supabase import load_env_file

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_temp/supabase_upload.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SupabaseUploader:
    def __init__(self):
        """Supabase ì—…ë¡œë” ì´ˆê¸°í™”"""
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')  # ì—…ë¡œë“œìš©ìœ¼ë¡œ service key ì‚¬ìš©
        
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_SERVICE_ROLE_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        self.api_url = f"{self.supabase_url}/rest/v1"
        self.headers = {
            'apikey': self.supabase_key,
            'Authorization': f'Bearer {self.supabase_key}',
            'Content-Type': 'application/json',
            'Prefer': 'return=minimal'
        }
    
    def test_connection(self) -> bool:
        """Supabase ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(
                f"{self.api_url}/iris_metrics?limit=1",
                headers=self.headers
            )
            if response.status_code == 200:
                logger.info("Supabase ì—°ê²° ì„±ê³µ")
                return True
            else:
                logger.error(f"Supabase ì—°ê²° ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return False
        except Exception as e:
            logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False
    
    def create_table_if_not_exists(self) -> bool:
        """í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„± (SQL íŒŒì¼ ì‹¤í–‰ ì•ˆë‚´)"""
        logger.info("í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì¤‘...")
        try:
            response = requests.get(
                f"{self.api_url}/iris_metrics?limit=1",
                headers=self.headers
            )
            if response.status_code == 200:
                logger.info("iris_metrics í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return True
            elif response.status_code == 404:
                logger.warning("iris_metrics í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                logger.info("ë¨¼ì € Supabase SQL Editorì—ì„œ supabase_schema.sqlì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return False
            else:
                logger.error(f"í…Œì´ë¸” í™•ì¸ ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"í…Œì´ë¸” í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def clear_existing_data(self) -> bool:
        """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì‚¬í•­)"""
        try:
            response = requests.delete(
                f"{self.api_url}/iris_metrics",
                headers=self.headers
            )
            if response.status_code in [200, 204]:
                logger.info("ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
                return True
            else:
                logger.error(f"ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
            return False
    
    def upload_batch(self, metrics: List[Dict], batch_size: int = 50) -> int:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì—…ë¡œë“œ"""
        total_uploaded = 0
        total_batches = (len(metrics) + batch_size - 1) // batch_size
        
        for i in range(0, len(metrics), batch_size):
            batch = metrics[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            logger.info(f"ë°°ì¹˜ {batch_num}/{total_batches} ì—…ë¡œë“œ ì¤‘ ({len(batch)}ê°œ)")
            
            try:
                response = requests.post(
                    f"{self.api_url}/iris_metrics",
                    headers=self.headers,
                    json=batch
                )
                
                if response.status_code in [200, 201]:
                    total_uploaded += len(batch)
                    logger.info(f"ë°°ì¹˜ {batch_num} ì—…ë¡œë“œ ì„±ê³µ")
                else:
                    logger.error(f"ë°°ì¹˜ {batch_num} ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                    logger.error(f"ì‘ë‹µ: {response.text}")
                    
            except Exception as e:
                logger.error(f"ë°°ì¹˜ {batch_num} ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        return total_uploaded
    
    def load_converted_data(self, filename: str = "data/iris_metrics_supabase_format.json") -> List[Dict]:
        """ë³€í™˜ëœ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('metrics', [])
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def verify_upload(self, expected_count: int) -> bool:
        """ì—…ë¡œë“œ ê²€ì¦"""
        try:
            response = requests.get(
                f"{self.api_url}/iris_metrics?select=count",
                headers=self.headers
            )
            
            if response.status_code == 200:
                # Supabase count ë°©ì‹
                response = requests.get(
                    f"{self.api_url}/iris_metrics?select=id&limit=1",
                    headers={**self.headers, 'Prefer': 'count=exact'}
                )
                
                if 'content-range' in response.headers:
                    count_str = response.headers['content-range']
                    actual_count = int(count_str.split('/')[-1])
                    
                    logger.info(f"ì—…ë¡œë“œ ê²€ì¦: {actual_count}/{expected_count}")
                    return actual_count == expected_count
                    
        except Exception as e:
            logger.error(f"ì—…ë¡œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
        
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_env_file()
    
    try:
        uploader = SupabaseUploader()
    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        print("ğŸ“ env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ .env íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    if not uploader.test_connection():
        print("âŒ Supabase ì—°ê²° ì‹¤íŒ¨")
        return
    
    # í…Œì´ë¸” í™•ì¸
    if not uploader.create_table_if_not_exists():
        print("âŒ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ğŸ“ ë¨¼ì € Supabase SQL Editorì—ì„œ supabase_schema.sqlì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë°ì´í„° ë¡œë“œ
    logger.info("ë³€í™˜ëœ ë°ì´í„° ë¡œë“œ ì¤‘...")
    metrics = uploader.load_converted_data()
    
    if not metrics:
        print("âŒ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸš€ {len(metrics)}ê°œ ë©”íŠ¸ë¦­ì„ Supabaseì— ì—…ë¡œë“œ ì‹œì‘")
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì—¬ë¶€ í™•ì¸
    clear_existing = input("ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower().strip()
    if clear_existing == 'y':
        uploader.clear_existing_data()
    
    # ì—…ë¡œë“œ ì‹¤í–‰
    uploaded_count = uploader.upload_batch(metrics)
    
    # ê²€ì¦
    if uploader.verify_upload(len(metrics)):
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}/{len(metrics)}ê°œ")
    else:
        print(f"âš ï¸ ì—…ë¡œë“œ ì™„ë£Œë˜ì—ˆì§€ë§Œ ê²€ì¦ ì‹¤íŒ¨: {uploaded_count}ê°œ ì—…ë¡œë“œë¨")

if __name__ == "__main__":
    main()
