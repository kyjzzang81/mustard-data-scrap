#!/usr/bin/env python3
"""
ìˆ˜ì§‘ëœ IRIS+ ë°ì´í„°ë¥¼ Supabase í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜í•˜ëŠ” ë„êµ¬
"""

import json
import os
from datetime import datetime
import logging
from typing import Dict, List, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_temp/supabase_conversion.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_env_file(env_file: str = '.env'):
    """í™˜ê²½ë³€ìˆ˜ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(env_file):
        logger.info(f"í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ ì¤‘: {env_file}")
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()
        logger.info("í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
    else:
        logger.info(f"í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ì—†ìŒ: {env_file} (ì„ íƒì‚¬í•­)")

class SupabaseConverter:
    def __init__(self):
        """
        Supabase ì—°ê²° ì •ë³´ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')
        
        if not self.supabase_url or not self.supabase_key:
            logger.warning("Supabase ì—°ê²° ì •ë³´ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (SUPABASE_URL, SUPABASE_ANON_KEY)")
            logger.info("í˜„ì¬ëŠ” ë°ì´í„° ë³€í™˜ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
    def load_collected_data(self, filename: str = "data/iris_metrics_complete.json") -> Dict:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def convert_metric_to_supabase_format(self, metric: Dict) -> Dict:
        """ë‹¨ì¼ ë©”íŠ¸ë¦­ì„ Supabase í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            details = metric.get('details', {})
            
            # ê¸°ë³¸ ì •ë³´ (ëª¨ë“  í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
            converted = {
                'title_en': metric.get('title', ''),
                'title_ko': None,  # ì¶”í›„ ë²ˆì—­ ì¶”ê°€
                'data_id': metric.get('data_id', ''),
                'relative_path': metric.get('relative_path', ''),
                'detail_url': metric.get('detail_url', '')
            }
            
            # ë©”íƒ€ë°ì´í„° (ì •ê·œí™”) - ëª¨ë“  í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            metadata = details.get('metadata', {})
            converted.update({
                'reporting_format': metadata.get('Reporting Format'),
                'metric_type': metadata.get('Metric Type'),
                'metric_level': metadata.get('Metric Level'),
                'iris_citation': metadata.get('IRIS Metric Citation')
            })
            
            # ìƒì„¸ ì •ë³´ë¥¼ ë‹¤êµ­ì–´ JSON êµ¬ì¡°ë¡œ ë³€í™˜ - ëª¨ë“  í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            
            # ì •ì˜
            converted['definition'] = {
                'en': details.get('definition'),
                'ko': None  # ì¶”í›„ ë²ˆì—­ ì¶”ê°€
            } if 'definition' in details else None
            
            # ì‚¬ìš© ê°€ì´ë“œë¼ì¸
            converted['usage_guidance'] = {
                'en': details.get('usage_guidance'),
                'ko': None  # ì¶”í›„ ë²ˆì—­ ì¶”ê°€
            } if 'usage_guidance' in details else None
            
            # ì„íŒ©íŠ¸ ì¹´í…Œê³ ë¦¬
            converted['impact_categories'] = {
                'en': details.get('impact_categories'),
                'ko': None  # ì¶”í›„ ë²ˆì—­ ì¶”ê°€
            } if 'impact_categories' in details else None
            
            # SDG ëª©í‘œ
            converted['sdg_goals'] = {
                'en': details.get('sdg_goals'),
                'ko': None  # ì¶”í›„ ë²ˆì—­ ì¶”ê°€
            } if 'sdg_goals' in details else None
            
            # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ (ì˜ë¬¸ë§Œ)
            converted['metric_history'] = details.get('metric_history')
            
            # ê´€ë ¨ ë©”íŠ¸ë¦­
            converted['related_metrics'] = details.get('related_metrics')
            
            # ë©”íƒ€ ì •ë³´ - ëª¨ë“  í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            converted.update({
                'scraped_at': details.get('scraped_at'),
                'translated_at': None,
                'success': details.get('success', True),
                'version': 'v5.3b'
            })
            
            return converted
            
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ {metric.get('data_id', 'unknown')} ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def convert_all_metrics(self, data: Dict) -> List[Dict]:
        """ëª¨ë“  ë©”íŠ¸ë¦­ì„ ë³€í™˜í•©ë‹ˆë‹¤."""
        metrics = data.get('metrics', [])
        converted_metrics = []
        
        logger.info(f"ì´ {len(metrics)}ê°œ ë©”íŠ¸ë¦­ ë³€í™˜ ì‹œì‘...")
        
        for i, metric in enumerate(metrics):
            converted = self.convert_metric_to_supabase_format(metric)
            if converted:
                converted_metrics.append(converted)
                
            if (i + 1) % 100 == 0:
                logger.info(f"{i + 1}/{len(metrics)} ë³€í™˜ ì™„ë£Œ")
        
        logger.info(f"ë³€í™˜ ì™„ë£Œ: {len(converted_metrics)}/{len(metrics)}ê°œ ì„±ê³µ")
        return converted_metrics
    
    def save_converted_data(self, converted_metrics: List[Dict], filename: str = "data/iris_metrics_supabase_format.json"):
        """ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            output_data = {
                "metadata": {
                    "total_metrics": len(converted_metrics),
                    "converted_at": datetime.now().isoformat(),
                    "format": "supabase_ready",
                    "language_support": ["en", "ko"],
                    "version": "v5.3b"
                },
                "metrics": converted_metrics
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ë³€í™˜ëœ ë°ì´í„° ì €ì¥: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def generate_sample_queries(self, converted_metrics: List[Dict]):
        """ìƒ˜í”Œ ì¿¼ë¦¬ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # Impact Categories ë¶„ì„
        impact_categories = set()
        sdg_goals = set()
        metric_types = set()
        
        for metric in converted_metrics:
            # ë©”íŠ¸ë¦­ íƒ€ì…
            if metric.get('metric_type'):
                metric_types.add(metric['metric_type'])
            
            # Impact Categories ì¶”ì¶œ
            impact_cat = metric.get('impact_categories')
            if impact_cat and isinstance(impact_cat, dict):
                en_data = impact_cat.get('en')
                if en_data and 'content' in en_data and 'headings' in en_data['content']:
                    for heading in en_data['content']['headings']:
                        if 'text' in heading:
                            impact_categories.add(heading['text'])
            
            # SDG ëª©í‘œ ì¶”ì¶œ
            sdg = metric.get('sdg_goals')
            if sdg and isinstance(sdg, dict):
                en_data = sdg.get('en')
                if en_data and 'content' in en_data and 'headings' in en_data['content']:
                    for heading in en_data['content']['headings']:
                        if 'text' in heading:
                            sdg_goals.add(heading['text'])
        
        # ìƒ˜í”Œ ì¿¼ë¦¬ íŒŒì¼ ìƒì„±
        queries = f"""-- IRIS+ ë©”íŠ¸ë¦­ ë°ì´í„° ìƒ˜í”Œ ì¿¼ë¦¬ë“¤
-- ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

-- 1. ëª¨ë“  Impact Categories ì¡°íšŒ
SELECT 
    jsonb_array_elements_text(
        jsonb_path_query_array(impact_categories, '$.en.content.headings[*].text')
    ) as category_name,
    COUNT(*) as metric_count
FROM iris_metrics 
WHERE impact_categories IS NOT NULL
GROUP BY category_name
ORDER BY metric_count DESC;

-- 2. íŠ¹ì • ì¹´í…Œê³ ë¦¬ ë©”íŠ¸ë¦­ ì¡°íšŒ (ì˜ˆ: Water)
SELECT title_en, data_id, metric_type
FROM iris_metrics 
WHERE impact_categories @> '{{"en": {{"content": {{"headings": [{{"text": "Water"}}]}}}}}}';

-- 3. SDG ëª©í‘œë³„ ë©”íŠ¸ë¦­ í†µê³„
SELECT 
    jsonb_array_elements_text(
        jsonb_path_query_array(sdg_goals, '$.en.content.headings[*].text')
    ) as sdg_name,
    COUNT(*) as metric_count
FROM iris_metrics 
WHERE sdg_goals IS NOT NULL
GROUP BY sdg_name
ORDER BY metric_count DESC;

-- 4. ë©”íŠ¸ë¦­ íƒ€ì…ë³„ ë¶„í¬
SELECT metric_type, COUNT(*) as count
FROM iris_metrics 
GROUP BY metric_type
ORDER BY count DESC;

-- 5. ì •ì˜ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì˜ë¬¸)
SELECT title_en, data_id, definition->>'en' as definition_en
FROM iris_metrics 
WHERE definition->>'en' ILIKE '%water%'
LIMIT 10;

-- 6. ì‚¬ìš© ê°€ì´ë“œë¼ì¸ì—ì„œ ê²€ìƒ‰
SELECT title_en, data_id
FROM iris_metrics 
WHERE usage_guidance->'en'->'content'->>'raw_text' ILIKE '%measurement%'
LIMIT 10;

-- 7. ë³µí•© ì¡°ê±´ ê²€ìƒ‰ (Water ì¹´í…Œê³ ë¦¬ + Clean Water SDG)
SELECT title_en, data_id, metric_type
FROM iris_metrics 
WHERE impact_categories @> '{{"en": {{"content": {{"headings": [{{"text": "Water"}}]}}}}}}' 
  AND sdg_goals @> '{{"en": {{"content": {{"headings": [{{"text": "Clean Water and Sanitation"}}]}}}}}}';

-- 8. ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ë©”íŠ¸ë¦­ë“¤
SELECT title_en, data_id, updated_at
FROM iris_metrics 
ORDER BY updated_at DESC
LIMIT 20;

-- ë°œê²¬ëœ ë°ì´í„° í†µê³„:
-- Impact Categories: {len(impact_categories)}ê°œ
-- SDG Goals: {len(sdg_goals)}ê°œ  
-- Metric Types: {len(metric_types)}ê°œ
-- ì£¼ìš” Impact Categories: {', '.join(list(impact_categories)[:10])}
-- ì£¼ìš” SDG Goals: {', '.join(list(sdg_goals)[:10])}
-- Metric Types: {', '.join(metric_types)}
"""
        
        with open('supabase_sample_queries.sql', 'w', encoding='utf-8') as f:
            f.write(queries)
        
        logger.info("ìƒ˜í”Œ ì¿¼ë¦¬ íŒŒì¼ ìƒì„±: supabase_sample_queries.sql")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ (ì„ íƒì‚¬í•­)
    load_env_file()
    
    converter = SupabaseConverter()
    
    # ë°ì´í„° ë¡œë“œ
    logger.info("ìˆ˜ì§‘ëœ ë°ì´í„° ë¡œë“œ ì¤‘...")
    data = converter.load_collected_data()
    
    if not data:
        print("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸš€ {len(data['metrics'])}ê°œ ë©”íŠ¸ë¦­ì„ Supabase í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œì‘")
    
    # ë³€í™˜
    converted_metrics = converter.convert_all_metrics(data)
    
    if converted_metrics:
        # ì €ì¥
        filename = converter.save_converted_data(converted_metrics)
        
        # ìƒ˜í”Œ ì¿¼ë¦¬ ìƒì„±
        converter.generate_sample_queries(converted_metrics)
        
        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ“ ë³€í™˜ëœ ë°ì´í„°: {filename}")
        print(f"ğŸ“Š ì„±ê³µ: {len(converted_metrics)}ê°œ")
        print(f"ğŸ“ ìƒ˜í”Œ ì¿¼ë¦¬: supabase_sample_queries.sql")
        
        # í†µê³„ ì¶œë ¥
        successful = len([m for m in converted_metrics if m.get('success', True)])
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {successful}/{len(converted_metrics)} ({successful/len(converted_metrics)*100:.1f}%)")
        
    else:
        print("âŒ ë³€í™˜ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
